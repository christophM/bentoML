---
title: "Lost In Translation"
description: |
 The performance of a machine learning model depends on more than the loss on unseen test data. The training data is merely the end product of multiple translations: The data is used to solve a prediction task, which is part of a tool, which again serves a goal. This blog post explores the chain of translations and the loss that occurs between each step.

author:
  - name: Christoph Molnar
date: 04-15-2019
slug: loss
output:
  radix::radix_article:
    self_contained: false
preview: images/translation-chain.png
creative_commons: CC BY-NC
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
When we train machine learning models, we measure the loss that occurs between the true outcome and the model predictions.
We focus on improving the loss, by trying out different models, by tuning the hyperparameters, by engineering the features.
Improving the loss becomes our sole focus.
The improvement in loss, the  gradient is not only backpropagated through the neural network, but also channeled through us.
Greedily we descent to the optimum.
Proudly we announce the end result.

"Researchers found that human dermatologists accurately identified 86.6 percent of skin cancers from a range of images, compared to 95 percent for the CNN." - [engadget 2018](https://www.engadget.com/2018/05/29/ai-outperforms-human-doctors-in-spotting-skin-cancer)


But what is the reason that high predictive performance is not a guarantee that the models are used in practice?
One reason: The nature of machine learning learning predictions is very, very narrow.
We have to make a lot of translations (i.e. narrow down the task), before we can solve it with machine learning.
Our goal might be to be really good at spotting skin cancer, ... or ....
But before we can do that, we first have to decide on the tool that we want to use to solve that problem.
Taking images over time?
Interactively chat with the patient?

Once this step is decided, we have to narrow the tool down to a prediction task:
Do we want to predict the likelihood that some mole is cancer?
That it will develop to cancer within the next 6 years?
Is it an image recognition task or do we also consider input from the patient?
Should it be images from special cameras? Or maybe smartphones?

Once we have settled this, we have to decide which data to take.
Do we take data from one doctor only?
Probably not.
How many practices / hospitals do we need to make this generalize?
Ah damn, we only get data from a couple of hospitals, but whatever.

Now, finally, we can start to measure for the selected data how well we can predict the cancer label.

Suddenly, your original goal of correctly identifying mole cancer narrowed down to:
Predict cancer from doctors images.
This dataset is biased https://arxiv.org/abs/1904.08818. 
Also the "AI" does not beat the doctor, but it "might" be better at the very narrow task of classifying images.



In the model training rabbit hole, it's easy to forget about the loss that occurred before: 
As a data scientist, after you got the data, and do the modeling, it is easy to forget the whole pipeline that led you there, and only focus on the loss ocurring between features and target.

Loss occurs way earlier.
Because before you dive into data, you have to translate you initial goal in multiple steps until you get to the data.


First there is some goal you have as a company, individual, institution or whatever.
The goal is the thing you want to achieve overall.
This is very high level and has nothing to do with machine learning or data.
If you are YouTube, a goal might be to increase the minutes watched per day.
Another goal could be to get more content creators onto the platform.

First translations: From goal to a process or tool to achieve the goal.
When you settled on a goal, you have to decide to achieve it. 

**Goal:** Can be anything

**Tool:** A product, a process. Some means to achieve that goal

**Prediction Task:** Thing you want to predict

**Data:** The data you use.


In the remainder of the post we will go through a few examples how this translation steps look like with three examples: customer relationship management, predictive policing and credit scoring.

Loss will always occur.
It's easy for me here to do the critique.
When you formulate problems as prediction tasks, you always have to make compromises, settle with the not so perfect solution.
Which is easy to critique.
The most important is that you have thought about the translations that have been made and how it affects the applicability of the predictions to the real world.
My advice: Make it explicit.
This blog post will help you with a few examples how to make those steps more explicit. 
Gives you a very rough template to do it (Goal -> Tool -> Prediction Task -> Data).


Another way to see it:
We start with a very broad goal, and end up with very specific, detailed data, where we have to decide which rows and columns to keep, what to use and so on.
We start with very broad intentions and narrow down the task until it is fit for machine learning.
With each narrowing, we are forced to specify our needs.
With each decision we loose something from our original goal.
We can even narrow down our goal so much that we end up with a wrong translation.


# Sending Vouchers to Customers

Imagine you manage a travel agency.
You sell trips to your customers, mostly to some very loyal customers and sometimes to new customers.
At the last trade show, the stand showing how you can sell more trips using data analytics and marketing had a great impression on you and you decide to hire them.

<img src='images/vouchers.jpg' alt='' title='Sending vouchers to customers to increase sales.'/>


**The Goal:** Selling more trips

The marketing consulting company advices you to send out vouchers to more customers.
With that translation of your goal to this specfic tool, the first loss in translation has occured:
Sending vouchers might not be the best tool.
Maybe uninvited vouchers will annoy your customers, maybe the low hanging fruits are a niche group of customers for whom you have the perfect trips, but they just don't know you yet.

But anyways, the decision has been made:

**The Tool:** Send vouchers to customers.


But wait!
Sending vouchers to everyone in your database would be too expensive.
Many customers are only file corpses in your drawers anyway.
The mailings cost more than zero (cause you decided that your customers will prefer good ol' physical paper mailings).
So, you need a way to send to "promising" / "high-value" customers.
We can translate this into a prediction task.
Why not predict which customer is most likely to book a trip in the next months.

**The prediction task:** Predict whether a customer will book a trip in the next 2 months.

The thinking is: If someone has a high likelihood do book, we want to make sure he books with us, and also the voucher might convince those that are not 100 percent sure whether to do a trip at all.

Another loss has occured by translating from the tool to the prediction task.
Maybe the customers who are likely to book will not be affected by the voucher, because they would have booked anyways.
You only loose money because they now book cheaper.

Now you have decided what to predict, the question is now which data to use.
You settle on past trips booked, demographic information, money spent on trips at your agency, time and date, ...
Ideally, you would have access to their bank account to see if they have enough money left, to their calenders to see if they have time, to their minds so you can read their thoughts.
But you only have your agencies database, so you use that.
Another translation has occured: From the prediction task to the data:

**The Data:** Customer demographics and prior trips.

A loss has ocurred as well.
This time you can measure it more directly, since you can measure how well the data predicts whether someone will book a trip in the next two weeks.
What's not easily measurable: The loss that ocurred by selecting a subset of the data, or by not using additional data.


# Predictive Policing

You are the head of the police department.
The executive arm of civil protection lies within your responsible hands.

<img src='images/predictive-policing.jpg' alt='' title='Working late to submit better predictions.'/>

**The Goal:** Keep the city safe.

Now, how exactly do you keep the city safe?
For example by catching criminals.
Even better, prevent crimes before they happen.
Also called "stop-and-frisk" in its extreme form.
So you translate the goal into:

**The Tool:** Prevent crimes by showing presence, doing stop-and-frisk.

A first loss has occurred:
Is this the most effective method?
Maybe the city could be made more secure by educating the people, by increasing the police staff to relief the burden of the many cases that are already on the table. 

Anyways, stop-and-frisk it is.
But your police staff can't be everywhere, you have to send them to specific areas.
Where to send them?
Send them to where you think most crime will happen.
This is a translation into a prediction task.

**Prediction Task:** For each place and time, predict likelihood of a crime.

A loss occurred: We could also predict who the most likely victims are or include the infromation which crimes are easily averted by presence and which not.

The data to use for those predictions is quite obvious: use spatial and time data of crimes that already ocurred in that time.
Additionally weather.

**The Data:**: Recent crimes, along with geolocation and time. Additional data: weather, occurrence of other events (e.g. soccer games).


Again, a loss occurred: We could have used completely different data sources that tell us more about the crime probabilities.
For example mobile location data or social media posting.
Also, by using the own crime data, there is a bias:
The closer the police looks, the more crimes it sees.
The other data might be dark:
Crimes that were never reported.
This loss is not reflected in our data, since we never expose our model to it, we only see the acurracy of predicting the crimes that we saw in the data.

# Credit Scoring

How can you trust someone to give you back money that you lend?
The answer in our society is credit scoring agencies.
In Germany the quasi-Monopoly is called the 'Schufa'.

<img src='images/schufa.jpg' alt='' title='Working late to submit better predictions.'/>

**Their goal:** Protect clients from credit risk.

How do they do it?

**Their tool:** Offer credit worthiness scores to lenders.

A loss occurred: Scores are not the only tool, they could also insure the credit.
They could allow lenders to deposit something.
They could assess customers individually (which, of course, would be a lot of work).

What does the score say?

**The prediction task:** Probability of loan default within 1 year (not sure if SCHUFA uses exactly this, but let's assume for now)

Sensible goal.
Still a loss occurred: Loan defaults after one year would be ignored.
From which data do we predict this?

**The Data:** Not revealed what data the SCHUFA uses, but data they have: current contracts with e.g. mobile providers, mail-order companies, credits that have not been paid and so on.

Loss in translation: Maybe a person never paid, e.g. because of an exploitve relationship, but this relationship is over.
This is not reflected in the database.
Also not in the data base: The people who don't get a loan in the first place, for whatever reason.
Those never show up in the database.
Self-reinforcing: People with a bad score don't get a loan.




# Lost in Translation

Every machine learning project has these decision that have to be made, which ultimately narrows down the question that can be answered.


With this post, I hope I could make it more explicit how we have to narrow down our original goal to a very specific slice of data.




# From Prediction to Action

Forgot to mention so far another, very important translation.
That is the translation back.

From your model, you get back predictions.
Those predictions don't spawn into the void to the pleasure of the universe, but rather inform decision and incite actions.
How that is done is crucial for the effectiviness of the model.

Back to YouTube: You have the predictions...

But this maybe for another blog post.


